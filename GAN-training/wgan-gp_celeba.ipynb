{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
    "parser.add_argument(\"--n_critic\", type=int, default=5, help=\"number of training steps for discriminator per iter\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=800, help=\"interval betwen image samples\")\n",
    "opt = parser.parse_args([])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./images/wgan-gp_celeba\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, DIM=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.DIM = DIM\n",
    "        \n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4 * 4 * 4 * DIM),\n",
    "            nn.BatchNorm1d(4 * 4 * 4 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4 * DIM, 2 * DIM, 2, stride=2),\n",
    "            nn.BatchNorm2d(2 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * DIM, DIM, 2, stride=2),\n",
    "            nn.BatchNorm2d(DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        deconv_out = nn.ConvTranspose2d(DIM, 3, 2, stride=2)\n",
    "\n",
    "        self.preprocess = preprocess\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        DIM = self.DIM\n",
    "        output = self.preprocess(z)\n",
    "        output = output.view(-1, 4 * DIM, 4, 4)\n",
    "        output = self.block1(output)\n",
    "        output = self.block2(output)\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.tanh(output)\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, DIM=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.DIM = DIM\n",
    "        \n",
    "        main = nn.Sequential(\n",
    "            nn.Conv2d(3, DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(DIM, 2 * DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(2 * DIM, 4 * DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.main = main\n",
    "        self.linear = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        DIM = self.DIM\n",
    "        \n",
    "        output = self.main(img)\n",
    "        output = output.view(-1, 4*4*4*DIM)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(opt.latent_dim)\n",
    "discriminator = Discriminator(opt.latent_dim)\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.CelebA(\n",
    "        \"/data\",\n",
    "        split='train',\n",
    "        download=False,\n",
    "        transform=transforms.Compose([\n",
    "                               transforms.Resize(32),\n",
    "                               transforms.CenterCrop(32),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ])\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = torch.as_tensor([0.5, 0.5, 0.5])[:, None, None].cuda()\n",
    "ds = torch.as_tensor([0.5, 0.5, 0.5])[:, None, None].cuda()\n",
    "\n",
    "z_static = Variable(Tensor(np.random.normal(0, 1, (64, opt.latent_dim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "batches_done = 0\n",
    "for epoch in tqdm(range(opt.n_epochs)):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % opt.n_critic == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "#             print(\n",
    "#                 \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "#                 % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "#             )\n",
    "\n",
    "#             if batches_done % opt.sample_interval == 0:\n",
    "#                 save_image(fake_imgs.data[:25], (save_dir + \"{}.png\").format(batches_done), nrow=5, normalize=True)\n",
    "\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                fake_imgs_static = generator(z_static)\n",
    "                fake_imgs_static.mul_(ds).add_(dm).clamp_(0, 1)\n",
    "                grid = make_grid(fake_imgs_static)\n",
    "                writer.add_image('images', grid, batches_done)\n",
    "                writer.add_scalar('Loss/d_loss', d_loss.item(), batches_done)\n",
    "                writer.add_scalar('Loss/g_loss', g_loss.item(), batches_done)\n",
    "            \n",
    "            batches_done += opt.n_critic\n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (64, opt.latent_dim))))\n",
    "fake_imgs = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = torch.as_tensor([0.5, 0.5, 0.5])[:, None, None].cuda()\n",
    "ds = torch.as_tensor([0.5, 0.5, 0.5])[:, None, None].cuda()\n",
    "fake_imgs.mul_(ds).add_(dm).clamp_(0, 1)\n",
    "img = make_grid(fake_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,14))\n",
    "plt.imshow(img.clone().detach().cpu().numpy().swapaxes(0, 2).swapaxes(0, 1).clip(0, 1), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './models/celeba_wgan-gp_generator_32.pth.tar'\n",
    "torch.save({'state_dict': generator.state_dict()}, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading\n",
    "\"\"\"\n",
    "model = Generator()\n",
    "checkpoint = torch.load(save_dir)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
